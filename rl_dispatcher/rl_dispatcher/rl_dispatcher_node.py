#!/usr/bin/env python3
#1.17ç”¨è™šæ‹Ÿrmfç¯å¢ƒè®­ç»ƒ
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import rclpy
from rclpy.node import Node
from rmf_fleet_msgs.msg import FleetState
from std_msgs.msg import String
from geometry_msgs.msg import Point
from rmf_custom_tasks_self.srv import SingleNavTask
import numpy as np
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import CheckpointCallback
import json
import time
import random
import threading
from datetime import datetime
import gymnasium as gym
from gymnasium import spaces

# ===================== å¼•å…¥åŒå¼•æ“ =====================
# 1. çœŸå®å¼•æ“ (Real Engine): å†…åµŒåœ¨å½“å‰æ–‡ä»¶ä¸­
# 2. è™šæ‹Ÿå¼•æ“ (Mock Engine): ä» mock_env.py å¯¼å…¥
try:
    from rl_dispatcher.mock_env import MockRMFEnv
except ImportError:
    # ä¸ºäº†é˜²æ­¢åœ¨ä¸åŒç¯å¢ƒä¸‹è·¯å¾„è¯†åˆ«é”™è¯¯ï¼Œå°è¯•ç›¸å¯¹å¯¼å…¥
    try:
        from mock_env import MockRMFEnv
    except ImportError:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° mock_env.pyã€‚è¯·ç¡®ä¿è¯¥æ–‡ä»¶å·²åˆ›å»ºåœ¨ rl_dispatcher ç›®å½•ä¸‹ã€‚")
        sys.exit(1)

# ===================== å¼•æ“ A: çœŸå® ROS ç¯å¢ƒ (Real Engine) =====================
class RLDispatchingEnv(gym.Env):
    """
    çœŸå® ROS ç¯å¢ƒï¼šä¾èµ– Gazebo ç‰©ç†ä»¿çœŸå’Œ RMF çŠ¶æ€åé¦ˆã€‚
    """
    metadata = {"render_modes": ["human"], "render_fps": 1}
    
    def __init__(self, node, render_mode=None):
        super().__init__()
        self.node = node
        self.render_mode = render_mode
        
        # 1. ç‰©ç†æœºå™¨äººé…ç½®
        self.robot_names = ["deliveryRobot_0", "deliveryRobot_1", "deliveryRobot_2"]
        self.robot_positions = {name: Point(x=0.0, y=0.0) for name in self.robot_names}
        self.robot_idle = {name: True for name in self.robot_names}
        self.robot_task_map = {}
        
        # 2. ä»»åŠ¡é˜Ÿåˆ—
        self.pending_tasks = []
        self.executing_tasks = {}
        self.completed_tasks = []
        self.failed_tasks = []
        
        # 3. ç»Ÿè®¡å˜é‡
        self.current_time = 0.0
        self.episode_steps = 0
        self.max_episode_steps = 500
        self.total_reward = 0.0
        
        # 4. ç©ºé—´å®šä¹‰ (å¿…é¡»ä¸ MockRMFEnv å®Œå…¨ä¸€è‡´)
        self.action_space = spaces.Discrete(len(self.robot_names))
        # 14ç»´çŠ¶æ€: 3x3(æœºå™¨äººçŠ¶æ€) + 3(ä»»åŠ¡) + 2(å…¨å±€)
        self.observation_space = spaces.Box(low=-1.0, high=1.0, shape=(14,), dtype=np.float32)
        
        # 5. å¥–åŠ±ç³»æ•°
        self.reward_coeff = {
            "distance": -0.1,
            "completion": 100.0,
            "idle_selection": -10.0,
            "timeout": -50.0,
            "step": -0.1
        }

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)
        self.robot_idle = {name: True for name in self.robot_names}
        self.robot_task_map = {}
        self.pending_tasks = []
        self.executing_tasks = {}
        self.completed_tasks = []
        self.current_time = 0.0
        self.episode_steps = 0
        self.total_reward = 0.0
        return self._get_observation(), {"total_reward": 0.0}

    def _get_observation(self):
        # 1. æœºå™¨äººçŠ¶æ€ (x, y, idle)
        robot_obs = []
        for name in self.robot_names:
            robot_obs.extend([
                self.robot_positions[name].x / 200.0,
                self.robot_positions[name].y / 50.0,
                1.0 if self.robot_idle[name] else 0.0
            ])
        
        # 2. ä»»åŠ¡çŠ¶æ€
        task_obs = [0.0, 0.0, 0.0]
        if self.pending_tasks:
            task = self.pending_tasks[0]
            task_obs = [
                task["x"] / 200.0,
                task["y"] / 50.0,
                min(task["wait_time"] / 100.0, 1.0)
            ]
            
        # 3. å…¨å±€çŠ¶æ€
        global_obs = [
            self.current_time / 1000.0,
            len(self.completed_tasks) / 10.0
        ]
        
        return np.array(robot_obs + task_obs + global_obs, dtype=np.float32)

    def step(self, action):
        self.episode_steps += 1
        self.current_time += 1.0
        reward = self.reward_coeff["step"]
        
        info = {"selected_robot": self.robot_names[action]}
        selected_robot = self.robot_names[action]
        
        # æ ¸å¿ƒé€»è¾‘ï¼šè¿™é‡Œåªè®¡ç®—å¥–åŠ±ï¼ŒçœŸæ­£çš„åŠ¨ä½œæ‰§è¡Œç”± Node ä¸­çš„ _call_nav_service å¤„ç†
        if not self.pending_tasks:
            truncated = self.episode_steps >= self.max_episode_steps
            return self._get_observation(), reward, False, truncated, info
            
        task = self.pending_tasks.pop(0)
        task_id = task["task_id"]
        info["task_id"] = task_id
        
        # å¥–åŠ±è®¡ç®—
        if not self.robot_idle[selected_robot]:
            reward += self.reward_coeff["idle_selection"]
            # æƒ©ç½šåæ”¾å›é˜Ÿåˆ—
            self.pending_tasks.insert(0, task)
        else:
            rx = self.robot_positions[selected_robot].x
            ry = self.robot_positions[selected_robot].y
            dist = np.sqrt((rx - task["x"])**2 + (ry - task["y"])**2)
            
            reward += self.reward_coeff["distance"] * dist
            
            # æ›´æ–°å†…éƒ¨çŠ¶æ€
            self.robot_idle[selected_robot] = False
            self.robot_task_map[selected_robot] = task_id
            self.executing_tasks[task_id] = {
                "robot": selected_robot,
                "start_time": self.current_time,
                "waypoint": task["waypoint"]
            }
            
        # è¶…æ—¶æ£€æŸ¥
        timeout_ids = []
        for tid, tinfo in self.executing_tasks.items():
            if self.current_time - tinfo["start_time"] > 60.0:
                reward += self.reward_coeff["timeout"]
                self.robot_idle[tinfo["robot"]] = True
                timeout_ids.append(tid)
        
        for tid in timeout_ids:
            del self.executing_tasks[tid]
            
        self.total_reward += reward
        truncated = self.episode_steps >= self.max_episode_steps
        
        return self._get_observation(), reward, False, truncated, info

    # è¾…åŠ©æ–¹æ³•ï¼šä¾› ROS å›è°ƒæ›´æ–°æ•°æ®
    def update_robot_position(self, name, x, y):
        if name in self.robot_positions:
            self.robot_positions[name].x = x
            self.robot_positions[name].y = y
            
    def add_task(self, tid, wp, x, y):
        self.pending_tasks.append({"task_id": tid, "waypoint": wp, "x": x, "y": y, "wait_time": 0.0})
        
    def complete_task(self, tid):
        if tid in self.executing_tasks:
            robot = self.executing_tasks[tid]["robot"]
            self.total_reward += self.reward_coeff["completion"]
            self.completed_tasks.append(tid)
            self.robot_idle[robot] = True
            del self.executing_tasks[tid]
            self.node.get_logger().info(f"ğŸ’° ä»»åŠ¡å®Œæˆå¥–åŠ± +100! (Robot: {robot})")

# ===================== æ ¸å¿ƒèŠ‚ç‚¹ï¼šåŒæ¨¡å¼è°ƒåº¦å™¨ =====================
class RLDispatcherNode(Node):
    def __init__(self):
        super().__init__("rl_dispatcher_node")
        self.get_logger().info("ğŸš€ åˆå§‹åŒ– RL è°ƒåº¦èŠ‚ç‚¹ (Train+Infer æ¨¡å¼)...")
        
        # ==================== ä¿®å¤ï¼šå‚æ•°å£°æ˜é€»è¾‘ ====================
        # 1. ä»¿çœŸæ—¶é—´é…ç½®
        if not self.has_parameter("use_sim_time"):
            self.declare_parameter("use_sim_time", True)
        self.set_parameters([rclpy.parameter.Parameter("use_sim_time", rclpy.Parameter.Type.BOOL, True)])

        # 2. æ¨¡å¼é…ç½® (Train / Infer)
        if not self.has_parameter("mode"):
            self.declare_parameter("mode", "train")
        
        self.mode = self.get_parameter("mode").get_parameter_value().string_value
        self.get_logger().info(f"ğŸ”µ å½“å‰æ¨¡å¼: [{self.mode.upper()}]")
        
        # ================== æ ¸å¿ƒï¼šåŒå¼•æ“åˆ‡æ¢ ==================
        if self.mode == "train":
            self.get_logger().info("ğŸš€ æ¨¡å¼: è®­ç»ƒ (TRAIN) - æŒ‚è½½ Mock è™šæ‹Ÿå¼•æ“")
            # è®­ç»ƒæ—¶ï¼Œä½¿ç”¨ Mock ç¯å¢ƒï¼Œä¸ä¾èµ– Gazebo/ROS è¯é¢˜
            self.rl_env = MockRMFEnv() 
            
        elif self.mode == "infer":
            self.get_logger().info("ğŸ¤– æ¨¡å¼: æ¨ç† (INFER) - æŒ‚è½½ Real çœŸå®å¼•æ“")
            # æ¨ç†æ—¶ï¼Œä½¿ç”¨ Real ç¯å¢ƒï¼Œä¾èµ– ROS è¯é¢˜å’ŒæœåŠ¡
            self.rl_env = RLDispatchingEnv(self, render_mode="human")
        else:
            self.get_logger().error("âŒ æœªçŸ¥æ¨¡å¼ã€‚è¯·ä½¿ç”¨ mode:=train æˆ– mode:=infer")
            sys.exit(1)
        # ========================================================

        # 3. åˆå§‹åŒ– RL æ¨¡å‹
        self.model = None
        self._init_rl_model()
        
        # 4. ä»…åœ¨ INFER æ¨¡å¼ä¸‹åˆå§‹åŒ– ROS æ¥å£
        if self.mode == "infer":
            self._init_ros_interfaces()

    def _init_ros_interfaces(self):
        """åˆå§‹åŒ– ROS è®¢é˜…ã€å‘å¸ƒå’ŒæœåŠ¡å®¢æˆ·ç«¯ (ä»…æ¨ç†æ¨¡å¼)"""
        self.get_logger().info("ğŸ”Œ æ­£åœ¨è¿æ¥ ROS æ¥å£...")
        
        # èˆªç‚¹åœ°å›¾
        self.waypoint_coords = {
            "n14": Point(x=80.84, y=-28.52), "n13": Point(x=84.44, y=-4.94),
            "n23": Point(x=182.80, y=-42.30), "s08": Point(x=96.61, y=-50.50),
            "s10": Point(x=122.10, y=-46.68), "west_koi_pond": Point(x=34.32, y=-10.13),
            "s11": Point(x=152.73, y=-43.00), "junction_south_west": Point(x=84.56, y=-38.81)
        }
        
        # è®¢é˜…å™¨
        self.create_subscription(FleetState, "/fleet_states", self.fleet_state_callback, 10)
        self.create_subscription(String, "/task_monitor/start", self.target_callback, 10)
        self.create_subscription(String, "/custom_task_completion", self.completion_callback, 10)
        
        # å®¢æˆ·ç«¯
        self.nav_client = self.create_client(SingleNavTask, "/submit_single_nav_task")
        
        # å†³ç­–å®šæ—¶å™¨ (1ç§’ä¸€æ¬¡)
        self.create_timer(1.0, self.infer_dispatch_callback)
        
        # å»é‡ç¼“å­˜
        self.processed_ids = set()
        
        self.get_logger().info("âœ… ROS æ¥å£è¿æ¥å®Œæ¯•")

    def _init_rl_model(self):
        """åŠ è½½æˆ–åˆ›å»º PPO æ¨¡å‹"""
        model_path = "./rl_models/dispatching_ppo_final"
        log_dir = "./rl_dispatching_tb_log/"
        
        if self.mode == "train":
            # åˆ›å»ºæ–°æ¨¡å‹
            self.model = PPO("MlpPolicy", self.rl_env, verbose=1, device='cpu', tensorboard_log=log_dir)
            self.checkpoint_callback = CheckpointCallback(save_freq=50000, save_path="./rl_models/", name_prefix="ppo")
            
        elif self.mode == "infer":
            # åŠ è½½å·²æœ‰æ¨¡å‹
            if os.path.exists(model_path + ".zip"):
                self.get_logger().info(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
                self.model = PPO.load(model_path, device='cpu')
            else:
                self.get_logger().error(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}.zipï¼Œè¯·å…ˆè¿è¡Œ train æ¨¡å¼ï¼")
                self.model = None

    # ===================== è®­ç»ƒé€»è¾‘ (æé€Ÿç‰ˆ) =====================
    def start_training(self, total_timesteps=1000000):
        """Mock å†…æ ¸é©±åŠ¨çš„æé€Ÿè®­ç»ƒ"""
        if self.mode != "train": return
            
        self.get_logger().info(f"ğŸ”¥ [æé€Ÿè®­ç»ƒ] å¼€å§‹è·‘ {total_timesteps} æ­¥...")
        start_t = time.time()
        
        # è¿™é‡Œçš„ learn ä¼šè‡ªåŠ¨é©±åŠ¨ MockRMFEnv.step()ï¼Œä¸ä¾èµ– ROS å›è°ƒ
        self.model.learn(total_timesteps=total_timesteps, callback=self.checkpoint_callback)
        
        duration = time.time() - start_t
        self.get_logger().info(f"âœ… è®­ç»ƒå®Œæˆï¼è€—æ—¶: {duration:.2f} ç§’")
        
        self.model.save("./rl_models/dispatching_ppo_final")
        self.get_logger().info("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ï¼Œå³å°†é€€å‡º...")
        rclpy.shutdown()

    # ===================== æ¨ç†é€»è¾‘ (å®æˆ˜ç‰ˆ) =====================
    def infer_dispatch_callback(self):
        """çœŸå®ç¯å¢ƒä¸‹çš„å‘¨æœŸæ€§è°ƒåº¦ï¼ˆä»…å¤„ç†red_cubeä»»åŠ¡ï¼‰"""
        # è¿‡æ»¤å‡ºä»…red_cubeå‰ç¼€çš„ä»»åŠ¡
        valid_tasks = [t for t in self.rl_env.pending_tasks if t["task_id"].startswith("red_cube_")]
        if not valid_tasks:
            self.get_logger().debug("ğŸ“­ æ— æœ‰æ•ˆç”¨æˆ·ä»»åŠ¡ï¼Œè·³è¿‡è°ƒåº¦")
            return
        
        # 1. è·å–çœŸå®çŠ¶æ€
        obs = self.rl_env._get_observation()
        
        # 2. æ¨¡å‹å†³ç­–
        action = 0
        if self.model:
            action, _ = self.model.predict(obs, deterministic=True)
            
            # å®‰å…¨é™çº§ï¼šå¦‚æœæ¨¡å‹é€‰äº†å¿™ç¢Œçš„è½¦ï¼Œå¼ºåˆ¶æ”¹ä¸ºç©ºé—²è½¦
            robot_name = self.rl_env.robot_names[action]
            if not self.rl_env.robot_idle[robot_name]:
                idle_indices = [i for i, name in enumerate(self.rl_env.robot_names) if self.rl_env.robot_idle[name]]
                if idle_indices:
                    action = random.choice(idle_indices)
                    self.get_logger().warn(f"ğŸ›¡ï¸ ä¿®æ­£ï¼šæ¨¡å‹é€‰äº†å¿™ç¢Œè½¦ï¼Œå¼ºåˆ¶æ”¹ä¸º {self.rl_env.robot_names[action]}")
        
        # 3. æ‰§è¡Œè°ƒåº¦ï¼ˆåªå¤„ç†ç¬¬ä¸€ä¸ªæœ‰æ•ˆä»»åŠ¡ï¼‰
        selected_robot = self.rl_env.robot_names[action]
        task = valid_tasks[0]  # åªå–ç¬¬ä¸€ä¸ªred_cubeä»»åŠ¡
        
        self._call_ros_service(selected_robot, task["task_id"], task["waypoint"])

    def _call_ros_service(self, robot, tid, wp):
        if not self.nav_client.service_is_ready():
            return
            
        req = SingleNavTask.Request()
        req.target_waypoint = wp
        req.fleet_name = "deliveryRobot"
        req.robot_name = robot
        req.priority = 1
        
        future = self.nav_client.call_async(req)
        # ä½¿ç”¨é—­åŒ…ä¿å­˜ä¸Šä¸‹æ–‡
        future.add_done_callback(lambda f: self._service_done(f, tid, robot))

    def _service_done(self, future, tid, robot):
        try:
            res = future.result()
            if res.success:
                self.get_logger().info(f"ğŸš€ [è°ƒåº¦æˆåŠŸ] {robot} -> ä»»åŠ¡ {tid}")
                # åªæœ‰æœåŠ¡è°ƒç”¨æˆåŠŸï¼Œæ‰ä»ç­‰å¾…é˜Ÿåˆ—ç§»é™¤ï¼Œå¹¶åœ¨ç¯å¢ƒä¸­æ ‡è®°ä¸ºå¿™ç¢Œ
                # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†åŒæ­¥ ROS çŠ¶æ€å’Œ RL ç¯å¢ƒçŠ¶æ€
                for i, t in enumerate(self.rl_env.pending_tasks):
                    if t["task_id"] == tid:
                        self.rl_env.pending_tasks.pop(i)
                        self.rl_env.robot_idle[robot] = False
                        self.rl_env.robot_task_map[robot] = tid
                        break
        except Exception as e:
            self.get_logger().error(f"æœåŠ¡è°ƒç”¨å¤±è´¥: {e}")

    # ===================== ROS å›è°ƒå‡½æ•° (ä»…æ›´æ–°æ•°æ®) =====================
    def fleet_state_callback(self, msg):
        if msg.name != "deliveryRobot": return
        for r in msg.robots:
            if r.name in self.rl_env.robot_names:
                self.rl_env.update_robot_position(r.name, r.location.x, r.location.y)
                # åŒé‡ç¡®è®¤ç©ºé—²çŠ¶æ€
                if not r.task_id:
                    self.rl_env.robot_idle[r.name] = True

    def target_callback(self, msg):
        """ä»…å¤„ç†æ— äººæœºå‘å¸ƒçš„red_cubeå‰ç¼€ä»»åŠ¡ï¼Œè¿‡æ»¤RMFåŸç”Ÿçš„direct_ä»»åŠ¡"""
        data = msg.data.split(",")
        if len(data) < 2:
            self.get_logger().warn(f"âš ï¸ æ— æ•ˆçš„ä»»åŠ¡æ ¼å¼: {msg.data}")
            return
        
        tid, wp = data[0].strip(), data[1].strip()
        
        # æ ¸å¿ƒè¿‡æ»¤ï¼šåªå¤„ç†red_cubeå‰ç¼€çš„ç”¨æˆ·ä»»åŠ¡ï¼Œå¿½ç•¥direct_å‰ç¼€çš„RMFåŸç”Ÿä»»åŠ¡
        if not tid.startswith("red_cube_"):
            self.get_logger().debug(f"ğŸ” å¿½ç•¥RMFåŸç”Ÿä»»åŠ¡: {tid} @ {wp}")
            return
        
        # å»é‡ï¼šé¿å…é‡å¤æ·»åŠ åŒä¸€ä»»åŠ¡
        if tid in self.processed_ids:
            self.get_logger().debug(f"âš ï¸ ä»»åŠ¡å·²å¤„ç†è¿‡: {tid}")
            return
        
        if wp in self.waypoint_coords:
            p = self.waypoint_coords[wp]
            self.rl_env.add_task(tid, wp, p.x, p.y)
            self.processed_ids.add(tid)
            self.get_logger().info(f"ğŸ“¥ æ”¶åˆ°æ–°ä»»åŠ¡: {tid} @ {wp}")
        else:
            self.get_logger().error(f"âŒ æœªçŸ¥èˆªç‚¹: {wp}ï¼Œä»»åŠ¡{tid}æ·»åŠ å¤±è´¥")

    def completion_callback(self, msg):
        tid = msg.data.split(",")[0].strip()
        self.rl_env.complete_task(tid)
        # æ¸…ç†å·²å®Œæˆä»»åŠ¡çš„å»é‡ç¼“å­˜ï¼Œå…è®¸ç›¸åŒä»»åŠ¡å†æ¬¡æäº¤
        if tid in self.processed_ids:
            self.processed_ids.remove(tid)
            self.get_logger().debug(f"ğŸ—‘ï¸  æ¸…ç†å·²å®Œæˆä»»åŠ¡ç¼“å­˜: {tid}")

# ===================== ä¸»ç¨‹åºå…¥å£ =====================
def main(args=None):
    rclpy.init(args=args)
    node = RLDispatcherNode()
    
    if node.mode == "train":
        # è®­ç»ƒæ¨¡å¼ï¼šå¼€å¯ç‹¬ç«‹çº¿ç¨‹è·‘è®­ç»ƒ
        train_thread = threading.Thread(
            target=node.start_training, 
            args=(1000000,),  # è·‘100ä¸‡æ­¥
            daemon=True
        )
        train_thread.start()
        # è¿™é‡Œçš„ spin ä¸»è¦æ˜¯ä¸ºäº†å“åº” shutdown ä¿¡å·ï¼Œå› ä¸º Mock ä¸éœ€è¦ ROS å›è°ƒ
        try:
            rclpy.spin(node)
        except SystemExit:
            pass
        train_thread.join()
        
    else:
        # æ¨ç†æ¨¡å¼ï¼šæ­£å¸¸çš„ ROS spin
        try:
            rclpy.spin(node)
        except KeyboardInterrupt:
            pass
        
    node.destroy_node()
    
    # é˜²æ­¢åŒé‡å…³æœºå¯¼è‡´çš„ RuntimeError
    if rclpy.ok():
        rclpy.shutdown()

if __name__ == "__main__":
    main()
