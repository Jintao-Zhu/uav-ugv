#!/usr/bin/env python3
import sys
sys.path.append("/home/suda/.local/lib/python3.10/site-packages")
import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, DurabilityPolicy, ReliabilityPolicy
from rmf_fleet_msgs.msg import FleetState
from std_msgs.msg import String
from geometry_msgs.msg import Point
from rmf_custom_tasks_self.srv import SingleNavTask
import numpy as np
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import CheckpointCallback
import json
import time
import random
from datetime import datetime
# å…³é”®ä¿®å¤ï¼šå¯¼å…¥Gymnasiumï¼ˆæ›¿ä»£åŸGymï¼‰
import gymnasium as gym
from gymnasium import spaces

# 1.17 æŠŠæ¨¡æ‹Ÿrmfçš„ä»£ç ä¹Ÿæ··åœ¨é‡Œé¢äº†

# ===================== ç¬¬ä¸€æ­¥ï¼šå®Œæ•´çš„RLè°ƒåº¦ç¯å¢ƒï¼ˆé€‚é…çœŸå®åœºæ™¯ï¼‰ =====================
class RLDispatchingEnv(gym.Env):  # å…³é”®ä¿®å¤1ï¼šç»§æ‰¿gym.EnvåŸºç±»
    """
    é€‚é…Gymnasiumæ ‡å‡†çš„RMFè°ƒåº¦ç¯å¢ƒ
    æ ¸å¿ƒæ¥å£ï¼šreset(), step(), render(), close()
    """
    metadata = {"render_modes": ["human"], "render_fps": 1}  # æ ‡å‡†å…ƒæ•°æ®
    
    def __init__(self, node, render_mode=None):
        # å…³é”®ä¿®å¤2ï¼šè°ƒç”¨åŸºç±»åˆå§‹åŒ–
        super().__init__()
        # ä¼ å…¥ROS2èŠ‚ç‚¹ç”¨äºæ—¥å¿—è¾“å‡º
        self.node = node
        self.render_mode = render_mode
        
        # 1. æ— äººè½¦é…ç½®ï¼ˆåŒ¹é…ä½ çš„RMFè½¦é˜Ÿï¼‰
        self.robot_names = ["deliveryRobot_0", "deliveryRobot_1", "deliveryRobot_2"]
        self.robot_positions = {name: Point(x=0.0, y=0.0) for name in self.robot_names}
        self.robot_idle = {name: True for name in self.robot_names}  # ç©ºé—²çŠ¶æ€
        self.robot_task_map = {}  # è®°å½•å°è½¦å½“å‰æ‰§è¡Œçš„ä»»åŠ¡ID {robot_name: task_id}
        
        # 2. ä»»åŠ¡é…ç½®
        self.pending_tasks = []  # å¾…æ‰§è¡Œä»»åŠ¡é˜Ÿåˆ—
        self.executing_tasks = {}  # æ‰§è¡Œä¸­ä»»åŠ¡ {task_id: {"robot": "", "start_time": 0.0, "waypoint": ""}}
        self.completed_tasks = []  # å·²å®Œæˆä»»åŠ¡
        self.failed_tasks = []  # å¤±è´¥ä»»åŠ¡
        
        # 3. è®­ç»ƒç›¸å…³é…ç½®
        self.current_time = 0.0  # å½“å‰ä»¿çœŸæ—¶é—´ï¼ˆç§’ï¼‰
        self.episode_steps = 0  # å•è½®è®­ç»ƒæ­¥æ•°
        self.max_episode_steps = 500  # å•è½®æœ€å¤§æ­¥æ•°
        self.total_reward = 0.0  # å•è½®æ€»å¥–åŠ±
        
        # 4. å…³é”®ä¿®å¤3ï¼šå®šä¹‰æ ‡å‡†çš„åŠ¨ä½œç©ºé—´å’ŒçŠ¶æ€ç©ºé—´ï¼ˆSB3å¿…éœ€ï¼‰
        # åŠ¨ä½œç©ºé—´ï¼šç¦»æ•£ç©ºé—´ï¼Œ0/1/2å¯¹åº”ä¸‰å°å°è½¦
        self.action_space = spaces.Discrete(len(self.robot_names))
        # çŠ¶æ€ç©ºé—´ï¼šBoxç©ºé—´ï¼Œç»´åº¦å’ŒåŸé€»è¾‘ä¸€è‡´ï¼Œå€¼èŒƒå›´å½’ä¸€åŒ–åˆ°[-1,1]
        self.observation_space = spaces.Box(
            low=-1.0,
            high=1.0,
            shape=(3*3 + 3 + 2,),  # åŸobservation_space_shape
            dtype=np.float32
        )
        
        # 5. å¥–åŠ±ç³»æ•°ï¼ˆå¯è°ƒï¼‰
        self.reward_coeff = {
            "distance": -0.1,    # è·ç¦»æƒ©ç½šï¼ˆè´Ÿæ•°ï¼Œè·ç¦»è¶Šè¿‘æƒ©ç½šè¶Šå°ï¼‰
            "completion": 100.0, # ä»»åŠ¡å®Œæˆå¥–åŠ±
            "idle_selection": -10.0,  # é€‰æ‹©å¿™ç¢Œå°è½¦çš„æƒ©ç½š
            "timeout": -50.0,    # ä»»åŠ¡è¶…æ—¶æƒ©ç½š
            "step": -0.1         # æ¯æ­¥åŸºç¡€æƒ©ç½šï¼ˆé¼“åŠ±å¿«é€Ÿå®Œæˆï¼‰
        }
        
        self.node.get_logger().info("ğŸ”§ RLç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œå°è½¦æ•°é‡ï¼š%d" % len(self.robot_names))

    def reset(self, seed=None, options=None):  # å…³é”®ä¿®å¤4ï¼šé€‚é…Gymnasiumçš„resetæ¥å£
        """é‡ç½®ç¯å¢ƒï¼ˆè®­ç»ƒæ—¶æ¯è½®å¼€å§‹è°ƒç”¨ï¼‰"""
        # å…³é”®ï¼šè®¾ç½®éšæœºç§å­ï¼ˆSB3è¦æ±‚ï¼‰
        super().reset(seed=seed)
        
        # é‡ç½®çŠ¶æ€
        self.robot_idle = {name: True for name in self.robot_names}
        self.robot_task_map = {}
        self.pending_tasks = []
        self.executing_tasks = {}
        self.completed_tasks = []
        self.failed_tasks = []
        
        self.current_time = 0.0
        self.episode_steps = 0
        self.total_reward = 0.0
        
        self.node.get_logger().debug("ğŸ”„ RLç¯å¢ƒå·²é‡ç½®")
        
        # å…³é”®ï¼šè¿”å›(obs, info)å…ƒç»„ï¼ˆGymnasiumæ ‡å‡†ï¼‰
        obs = self._get_observation()
        info = {"total_reward": 0.0, "completed_tasks": 0}
        return obs, info

    def _get_observation(self):
        """æ„å»ºçŠ¶æ€å‘é‡ï¼ˆä¾›RLæ¨¡å‹è¾“å…¥ï¼‰"""
        # 1. å°è½¦çŠ¶æ€ï¼šx, y, æ˜¯å¦ç©ºé—²ï¼ˆ1/0ï¼‰
        robot_obs = []
        for name in self.robot_names:
            robot_obs.extend([
                self.robot_positions[name].x / 200.0,  # å½’ä¸€åŒ–ï¼ˆä½ çš„èˆªç‚¹æœ€å¤§xçº¦180ï¼‰
                self.robot_positions[name].y / 50.0,   # å½’ä¸€åŒ–ï¼ˆyçº¦-50~0ï¼‰
                1.0 if self.robot_idle[name] else 0.0
            ])
        
        # 2. å¾…æ‰§è¡Œä»»åŠ¡çŠ¶æ€ï¼ˆå–ç¬¬ä¸€ä¸ªï¼‰
        task_obs = [0.0, 0.0, 0.0]  # x, y, wait_time
        if self.pending_tasks:
            task = self.pending_tasks[0]
            task_obs = [
                task["x"] / 200.0,
                task["y"] / 50.0,
                min(task["wait_time"] / 100.0, 1.0)  # ç­‰å¾…æ—¶é—´å½’ä¸€åŒ–ï¼ˆæœ€å¤§100ç§’ï¼‰
            ]
        
        # 3. å…¨å±€çŠ¶æ€
        global_obs = [
            self.current_time / 1000.0,  # æ—¶é—´å½’ä¸€åŒ–
            len(self.completed_tasks) / 10.0  # å·²å®Œæˆä»»åŠ¡æ•°å½’ä¸€åŒ–ï¼ˆæœ€å¤§10ä¸ªï¼‰
        ]
        
        # åˆå¹¶ä¸ºçŠ¶æ€å‘é‡
        obs = np.array(robot_obs + task_obs + global_obs, dtype=np.float32)
        return obs

    def step(self, action):  # å…³é”®ä¿®å¤5ï¼šä¿æŒé€»è¾‘ä¸å˜ï¼Œä½†è¿”å›æ ¼å¼é€‚é…Gymnasium
        """æ‰§è¡ŒåŠ¨ä½œï¼ˆæ ¸å¿ƒï¼šé€‰è½¦+è®¡ç®—å¥–åŠ±ï¼‰"""
        self.episode_steps += 1
        self.current_time += 1.0
        reward = 0.0
        terminated = False  # ä»»åŠ¡å®Œæˆ/å¤±è´¥å¯¼è‡´çš„ç»ˆæ­¢
        truncated = False   # æ­¥æ•°è¶…é™å¯¼è‡´çš„æˆªæ–­
        info = {
            "selected_robot": "",
            "task_id": "",
            "distance": 0.0,
            "reward_breakdown": {},
            "total_reward": 0.0
        }
        
        # 1. åŸºç¡€æƒ©ç½šï¼šæ¯æ­¥éƒ½æœ‰ï¼ˆé¼“åŠ±å¿«é€Ÿå®Œæˆï¼‰
        reward += self.reward_coeff["step"]
        info["reward_breakdown"]["step"] = self.reward_coeff["step"]
        
        # 2. åŠ¨ä½œæ˜ å°„ï¼šactionâ†’å°è½¦å
        selected_robot = self.robot_names[action]
        info["selected_robot"] = selected_robot
        
        # 3. è‹¥æ— å¾…æ‰§è¡Œä»»åŠ¡ï¼Œç›´æ¥è¿”å›
        if not self.pending_tasks:
            info["reward_breakdown"]["no_task"] = 0.0
            truncated = self.episode_steps >= self.max_episode_steps  # æ­¥æ•°è¶…é™æˆªæ–­
            return self._get_observation(), reward, terminated, truncated, info
        
        # 4. å–å‡ºç¬¬ä¸€ä¸ªå¾…æ‰§è¡Œä»»åŠ¡
        task = self.pending_tasks.pop(0)
        task_id = task["task_id"]
        info["task_id"] = task_id
        
        # 5. æ£€æŸ¥é€‰ä¸­çš„å°è½¦æ˜¯å¦ç©ºé—²
        if not self.robot_idle[selected_robot]:
            # æƒ©ç½šï¼šé€‰æ‹©å¿™ç¢Œå°è½¦
            reward += self.reward_coeff["idle_selection"]
            info["reward_breakdown"]["idle_selection"] = self.reward_coeff["idle_selection"]
            # ä»»åŠ¡æ”¾å›é˜Ÿåˆ—
            self.pending_tasks.insert(0, task)
            self.node.get_logger().warn(f"âš ï¸ é€‰ä¸­å¿™ç¢Œå°è½¦{selected_robot}ï¼Œæƒ©ç½š{self.reward_coeff['idle_selection']}")
        else:
            # 6. è®¡ç®—å°è½¦åˆ°ç›®æ ‡çš„è·ç¦»æƒ©ç½š
            robot_pos = self.robot_positions[selected_robot]
            distance = np.sqrt((robot_pos.x - task["x"])**2 + (robot_pos.y - task["y"])**2)
            distance_reward = self.reward_coeff["distance"] * distance
            reward += distance_reward
            info["distance"] = distance
            info["reward_breakdown"]["distance"] = distance_reward
            
            # 7. æ ‡è®°å°è½¦ä¸ºå¿™ç¢Œï¼Œä»»åŠ¡ä¸ºæ‰§è¡Œä¸­
            self.robot_idle[selected_robot] = False
            self.robot_task_map[selected_robot] = task_id
            self.executing_tasks[task_id] = {
                "robot": selected_robot,
                "start_time": self.current_time,
                "waypoint": task["waypoint"],
                "target_x": task["x"],
                "target_y": task["y"]
            }
            self.node.get_logger().info(f"ğŸ¤– è°ƒåº¦{selected_robot}æ‰§è¡Œä»»åŠ¡{task_id}ï¼Œè·ç¦»{distance:.2f}ç±³ï¼Œå¥–åŠ±{distance_reward:.2f}")
        
        # 8. æ£€æŸ¥ä»»åŠ¡è¶…æ—¶ï¼ˆæ‰§è¡Œè¶…è¿‡60ç§’ç®—è¶…æ—¶ï¼‰
        timeout_tasks = []
        for tid, t_info in self.executing_tasks.items():
            if self.current_time - t_info["start_time"] > 60.0:
                # è¶…æ—¶æƒ©ç½š
                reward += self.reward_coeff["timeout"]
                info["reward_breakdown"]["timeout"] = self.reward_coeff["timeout"]
                self.failed_tasks.append(tid)
                timeout_tasks.append(tid)
                # é‡Šæ”¾å°è½¦
                self.robot_idle[t_info["robot"]] = True
                del self.robot_task_map[t_info["robot"]]
        
        # ç§»é™¤è¶…æ—¶ä»»åŠ¡
        for tid in timeout_tasks:
            del self.executing_tasks[tid]
        
        # 9. æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ­¥æ•°ï¼ˆtruncated=Trueï¼‰
        if self.episode_steps >= self.max_episode_steps:
            truncated = True
            self.node.get_logger().info(f"ğŸ”š å•è½®è®­ç»ƒç»“æŸï¼ˆæ­¥æ•°ä¸Šé™ï¼‰ï¼Œæ€»å¥–åŠ±ï¼š{self.total_reward:.2f}ï¼Œå®Œæˆä»»åŠ¡æ•°ï¼š{len(self.completed_tasks)}")
        
        # 10. æ›´æ–°æ€»å¥–åŠ±
        self.total_reward += reward
        info["total_reward"] = self.total_reward
        
        # å…³é”®ï¼šè¿”å›(obs, reward, terminated, truncated, info)å…ƒç»„ï¼ˆGymnasiumæ ‡å‡†ï¼‰
        return self._get_observation(), reward, terminated, truncated, info

    def render(self):  # å…³é”®ä¿®å¤6ï¼šå®ç°æ ‡å‡†renderæ–¹æ³•ï¼ˆç©ºå®ç°å³å¯ï¼‰
        """æ¸²æŸ“ç¯å¢ƒï¼ˆæ— éœ€å¯è§†åŒ–ï¼Œç©ºå®ç°ï¼‰"""
        if self.render_mode == "human":
            self.node.get_logger().info(f"ğŸ“Š æ¸²æŸ“ï¼šå½“å‰æ­¥æ•°{self.episode_steps}ï¼Œæ€»å¥–åŠ±{self.total_reward:.2f}")

    def close(self):  # å…³é”®ä¿®å¤7ï¼šå®ç°æ ‡å‡†closeæ–¹æ³•
        """å…³é—­ç¯å¢ƒï¼ˆç©ºå®ç°ï¼‰"""
        pass

    def add_task(self, task_id, waypoint, x, y):
        """æ·»åŠ æ–°ä»»åŠ¡åˆ°å¾…æ‰§è¡Œé˜Ÿåˆ—"""
        self.pending_tasks.append({
            "task_id": task_id,
            "waypoint": waypoint,
            "x": x,
            "y": y,
            "wait_time": 0.0
        })
        # æ›´æ–°ä»»åŠ¡ç­‰å¾…æ—¶é—´çš„å®šæ—¶å™¨ï¼ˆåœ¨ROSèŠ‚ç‚¹ä¸­å¤„ç†ï¼‰
        self.node.get_logger().info(f"ğŸ“¥ æ·»åŠ æ–°ä»»åŠ¡ï¼š{task_id} -> {waypoint} (x:{x:.2f}, y:{y:.2f})")

    def complete_task(self, task_id):
        """ä»»åŠ¡å®Œæˆå›è°ƒï¼ˆç”±ROSèŠ‚ç‚¹è°ƒç”¨ï¼‰"""
        if task_id not in self.executing_tasks:
            self.node.get_logger().warn(f"âš ï¸ ä»»åŠ¡{task_id}ä¸åœ¨æ‰§è¡Œä¸­ï¼Œè·³è¿‡å®Œæˆå›è°ƒ")
            return
        
        # 1. è·å–ä»»åŠ¡ä¿¡æ¯
        task_info = self.executing_tasks[task_id]
        robot_name = task_info["robot"]
        
        # 2. ä»»åŠ¡å®Œæˆå¥–åŠ±
        self.total_reward += self.reward_coeff["completion"]
        self.node.get_logger().info(f"ğŸ¯ ä»»åŠ¡{task_id}å®Œæˆï¼å¥–åŠ±{self.reward_coeff['completion']}ï¼Œæ‰§è¡Œå°è½¦ï¼š{robot_name}")
        
        # 3. æ›´æ–°çŠ¶æ€
        self.completed_tasks.append(task_id)
        del self.executing_tasks[task_id]
        self.robot_idle[robot_name] = True
        del self.robot_task_map[robot_name]

    def update_robot_position(self, robot_name, x, y):
        """æ›´æ–°å°è½¦ä½ç½®ï¼ˆç”±ROSèŠ‚ç‚¹å›è°ƒè°ƒç”¨ï¼‰"""
        if robot_name in self.robot_positions:
            self.robot_positions[robot_name].x = x
            self.robot_positions[robot_name].y = y

    def update_task_wait_time(self):
        """æ›´æ–°å¾…æ‰§è¡Œä»»åŠ¡çš„ç­‰å¾…æ—¶é—´"""
        for task in self.pending_tasks:
            task["wait_time"] += 1.0

# ===================== ç¬¬äºŒæ­¥ï¼šRLè°ƒåº¦èŠ‚ç‚¹ï¼ˆè®­ç»ƒ+æ¨ç†ä¸€ä½“åŒ–ï¼‰ =====================
class RLDispatcherNode(Node):
    def __init__(self):
        super().__init__("rl_dispatcher_node")
        self.get_logger().info("ğŸš€ åˆå§‹åŒ–RLè°ƒåº¦èŠ‚ç‚¹ï¼ˆè®­ç»ƒ+æ¨ç†æ¨¡å¼ï¼‰...")
        
        # 1. ä»¿çœŸæ—¶é—´é…ç½®
        if not self.has_parameter("use_sim_time"):
            self.declare_parameter("use_sim_time", True)
        self.set_parameters([rclpy.parameter.Parameter("use_sim_time", rclpy.Parameter.Type.BOOL, True)])
        
        # 2. æ ¸å¿ƒé…ç½®ï¼šè®­ç»ƒ/æ¨ç†æ¨¡å¼ï¼ˆé€šè¿‡å‚æ•°æ§åˆ¶ï¼‰
        self.declare_parameter("mode", "train")  # train / infer
        self.mode = self.get_parameter("mode").get_parameter_value().string_value
        self.get_logger().info(f"ğŸ”§ å½“å‰æ¨¡å¼ï¼š{self.mode}")
        
        # 3. åˆå§‹åŒ–RLç¯å¢ƒï¼ˆé€‚é…æ–°çš„Gymnasiumç¯å¢ƒï¼‰
        self.rl_env = RLDispatchingEnv(self, render_mode="human")
        
        # 4. åˆå§‹åŒ–RLæ¨¡å‹
        self.model = None
        self._init_rl_model()
        
        # 5. ROSè®¢é˜…å™¨
        # 5.1 è®¢é˜…å°è½¦çŠ¶æ€
        self.fleet_state_sub = self.create_subscription(
            FleetState,
            "/fleet_states",
            self.fleet_state_callback,
            10
        )
        # 5.2 è®¢é˜…æ–°ä»»åŠ¡ï¼ˆæ— äººæœºå‘ç°ç›®æ ‡ï¼‰
        self.target_sub = self.create_subscription(
            String,
            "/task_monitor/start",
            self.target_callback,
            10
        )
        # 5.3 è®¢é˜…ä»»åŠ¡å®Œæˆä¿¡å·ï¼ˆç›‘æ§èŠ‚ç‚¹å‘å¸ƒï¼‰
        self.completion_sub = self.create_subscription(
            String,
            "/custom_task_completion",
            self.completion_callback,
            10
        )
        
        # 6. ROSæœåŠ¡å®¢æˆ·ç«¯ï¼ˆè°ƒç”¨è‡ªå®šä¹‰ä»»åŠ¡æœåŠ¡ï¼‰
        self.nav_client = self.create_client(SingleNavTask, "/submit_single_nav_task")
        while not self.nav_client.wait_for_service(timeout_sec=5.0):
            if not rclpy.ok():
                self.get_logger().error("âŒ ç­‰å¾…æœåŠ¡æ—¶èŠ‚ç‚¹é€€å‡ºï¼")
                return
            self.get_logger().info("â³ ç­‰å¾…/submit_single_nav_taskæœåŠ¡å¯ç”¨...")
        self.get_logger().info("âœ… å·²è¿æ¥è‡ªå®šä¹‰ä»»åŠ¡æœåŠ¡ï¼")
        
        # 7. èˆªç‚¹åæ ‡æ˜ å°„ï¼ˆå¤ç”¨ä½ çš„ç›‘æ§èŠ‚ç‚¹é…ç½®ï¼‰
        self.waypoint_coords = self._init_waypoint_coords()
        
        # 8. å®šæ—¶å™¨
        # 8.1 çŠ¶æ€æ›´æ–°å®šæ—¶å™¨ï¼ˆ1ç§’/æ¬¡ï¼‰
        self.state_timer = self.create_timer(1.0, self.state_timer_callback)
        # 8.2 è®­ç»ƒ/æ¨ç†å®šæ—¶å™¨ï¼ˆè®­ç»ƒæ—¶2ç§’å†³ç­–ä¸€æ¬¡ï¼Œæ¨ç†æ—¶1ç§’ï¼‰
        self.dispatch_timer = self.create_timer(2.0 if self.mode == "train" else 1.0, self.dispatch_callback)
        
        # 9. å»é‡+é˜²æŠ–é€»è¾‘
        self.processed_target_ids = set()
        self.last_target_time = 0.0
        self.DEBOUNCE_DELAY = 1.0
        
        self.get_logger().info("âœ… RLè°ƒåº¦èŠ‚ç‚¹åˆå§‹åŒ–å®Œæˆï¼")

    def _init_waypoint_coords(self):
        """èˆªç‚¹åæ ‡æ˜ å°„ï¼ˆå’Œä½ çš„ç›‘æ§èŠ‚ç‚¹å®Œå…¨ä¸€è‡´ï¼‰"""
        waypoint_coords = {}
        waypoint_coords["junction_n01"] = Point(x=1.57, y=-45.93)
        waypoint_coords["n08"] = Point(x=59.61, y=-7.42)
        waypoint_coords["n14"] = Point(x=80.84, y=-28.52)
        waypoint_coords["n13"] = Point(x=84.44, y=-4.94)
        waypoint_coords["n23"] = Point(x=182.80, y=-42.30)
        waypoint_coords["west_koi_pond"] = Point(x=34.32, y=-10.13)
        waypoint_coords["s08"] = Point(x=96.61, y=-50.50)
        waypoint_coords["s10"] = Point(x=122.10, y=-46.68)
        waypoint_coords["s11"] = Point(x=152.73, y=-43.00)
        waypoint_coords["junction_south_west"] = Point(x=84.56, y=-38.81)
        return waypoint_coords

    def _init_rl_model(self):
        """åˆå§‹åŒ–RLæ¨¡å‹ï¼ˆè®­ç»ƒ/æ¨ç†æ¨¡å¼ï¼‰"""
        if self.mode == "train":
            # è®­ç»ƒæ¨¡å¼ï¼šæ–°å»ºæ¨¡å‹
            self.get_logger().info("ğŸ“š åˆå§‹åŒ–PPOè®­ç»ƒæ¨¡å‹...")
            self.model = PPO(
                "MlpPolicy",
                self.rl_env,
                verbose=1,
                learning_rate=3e-4,
                n_steps=2048,
                batch_size=64,
                gamma=0.99,
                tensorboard_log="./rl_dispatching_tb_log/",
                device='cpu'  # å…³é”®ï¼šå¼ºåˆ¶ä½¿ç”¨CPU
            )
            # è®­ç»ƒæ£€æŸ¥ç‚¹å›è°ƒï¼ˆæ¯1000æ­¥ä¿å­˜ä¸€æ¬¡ï¼‰
            self.checkpoint_callback = CheckpointCallback(
                save_freq=1000,
                save_path="./rl_models/",
                name_prefix="dispatching_ppo"
            )
        elif self.mode == "infer":
            # æ¨ç†æ¨¡å¼ï¼šåŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            self.get_logger().info("ğŸ” åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
            try:
                self.model = PPO.load(
                    "./rl_models/dispatching_ppo_final",
                    device='cpu'  # æ¨ç†æ—¶ä¹Ÿå¼ºåˆ¶ç”¨CPU
                )
                # å…³é”®ï¼šåŠ è½½æ¨¡å‹åè®¾ç½®ç¯å¢ƒ
                self.model.set_env(self.rl_env)
                self.get_logger().info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            except Exception as e:
                self.get_logger().error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
                # åŠ è½½å¤±è´¥æ—¶é€€åŒ–ä¸ºéšæœºé€‰è½¦
                self.model = None
        else:
            self.get_logger().error(f"âŒ æ— æ•ˆæ¨¡å¼ï¼š{self.mode}ï¼Œè¯·é€‰æ‹©train/infer")
            rclpy.shutdown()


    def fleet_state_callback(self, msg):
        """æ›´æ–°å°è½¦ä½ç½®å’ŒçŠ¶æ€"""
        if msg.name != "deliveryRobot":
            return
        for robot in msg.robots:
            robot_name = robot.name
            if robot_name in self.rl_env.robot_names:
                # æ›´æ–°ä½ç½®
                self.rl_env.update_robot_position(robot_name, robot.location.x, robot.location.y)
                # æ›´æ–°ç©ºé—²çŠ¶æ€ï¼ˆtask_idä¸ºç©ºåˆ™ç©ºé—²ï¼‰
                self.rl_env.robot_idle[robot_name] = (robot.task_id == "")
                self.get_logger().debug(
                    f"ğŸ” æ›´æ–°å°è½¦çŠ¶æ€ï¼š{robot_name} (x:{robot.location.x:.2f}, y:{robot.location.y:.2f}) ç©ºé—²: {self.rl_env.robot_idle[robot_name]}"
                )

    def target_callback(self, msg):
        """æ¥æ”¶æ–°ä»»åŠ¡ï¼ˆæ— äººæœºå‘ç°ç›®æ ‡ï¼‰"""
        # è§£ææ¶ˆæ¯ï¼štask_id,target_waypoint
        data = msg.data.split(",")
        if len(data) < 2:
            self.get_logger().error("âŒ ç›®æ ‡æ¶ˆæ¯æ ¼å¼é”™è¯¯ï¼š%s", msg.data)
            return
        
        target_id = data[0].strip()
        target_waypoint = data[1].strip()
        
        # é˜²æŠ–+å»é‡
        current_time = self.get_clock().now().nanoseconds / 1e9
        if current_time - self.last_target_time < self.DEBOUNCE_DELAY:
            self.get_logger().debug(f"âš ï¸ é˜²æŠ–è¿‡æ»¤ï¼š{target_id}")
            return
        if target_id in self.processed_target_ids:
            self.get_logger().debug(f"âš ï¸ å»é‡è¿‡æ»¤ï¼š{target_id}")
            return
        
        # è®°å½•ä»»åŠ¡IDå’Œæ—¶é—´
        self.processed_target_ids.add(target_id)
        self.last_target_time = current_time
        
        # è·å–èˆªç‚¹åæ ‡
        if target_waypoint not in self.waypoint_coords:
            self.get_logger().error("âŒ æœªçŸ¥èˆªç‚¹ï¼š%s", target_waypoint)
            return
        target_coords = self.waypoint_coords[target_waypoint]
        
        # æ·»åŠ åˆ°RLç¯å¢ƒ
        self.rl_env.add_task(target_id, target_waypoint, target_coords.x, target_coords.y)

    def completion_callback(self, msg):
        """æ¥æ”¶ä»»åŠ¡å®Œæˆä¿¡å·ï¼ˆç›‘æ§èŠ‚ç‚¹å‘å¸ƒï¼‰"""
        # è§£ææ¶ˆæ¯ï¼štask_id,robot_name,waypoint,timestamp
        data = msg.data.split(",")
        if len(data) < 1:
            self.get_logger().error("âŒ å®Œæˆæ¶ˆæ¯æ ¼å¼é”™è¯¯ï¼š%s", msg.data)
            return
        task_id = data[0].strip()
        # é€šçŸ¥RLç¯å¢ƒä»»åŠ¡å®Œæˆ
        self.rl_env.complete_task(task_id)

    def state_timer_callback(self):
        """çŠ¶æ€æ›´æ–°å®šæ—¶å™¨ï¼ˆ1ç§’/æ¬¡ï¼‰"""
        # æ›´æ–°ä»»åŠ¡ç­‰å¾…æ—¶é—´
        self.rl_env.update_task_wait_time()
        # è®­ç»ƒæ¨¡å¼ï¼šæ›´æ–°ç¯å¢ƒæ—¶é—´
        if self.mode == "train":
            self.rl_env.current_time += 1.0

    def dispatch_callback(self):
        """RLå†³ç­–+ä»»åŠ¡è°ƒåº¦ï¼ˆå®šæ—¶å™¨è§¦å‘ï¼‰"""
        # 1. åˆ¤ç©ºï¼šæ— å¾…æ‰§è¡Œä»»åŠ¡åˆ™è·³è¿‡
        if not self.rl_env.pending_tasks:
            return
        
        # 2. è·å–å½“å‰çŠ¶æ€ï¼ˆé€‚é…æ–°çš„resetè¿”å›æ ¼å¼ï¼‰
        obs = self.rl_env._get_observation()
        
        # 3. RLå†³ç­–ï¼ˆæ–°å¢å®Œæ•´é˜²æŠ¤é€»è¾‘ï¼‰
        action = 0  # é»˜è®¤åŠ¨ä½œ
        # å…ˆç­›é€‰æ‰€æœ‰ç©ºé—²å°è½¦çš„ç´¢å¼•
        idle_robot_indices = [i for i, name in enumerate(self.rl_env.robot_names) if self.rl_env.robot_idle[name]]
        all_robot_indices = list(range(len(self.rl_env.robot_names)))  # [0,1,2]
        
        if self.mode == "train":
            # è®­ç»ƒæ¨¡å¼ï¼šæ¢ç´¢+åˆ©ç”¨ + ç©ºé—²å°è½¦ä¼˜å…ˆ
            if self.model:
                # æ¨¡å‹é¢„æµ‹åŸå§‹åŠ¨ä½œ
                raw_action, _states = self.model.predict(obs, deterministic=False)
                # é˜²æŠ¤1ï¼šå¦‚æœæœ‰ç©ºé—²å°è½¦â†’åªåœ¨ç©ºé—²å°è½¦ä¸­é€‰
                if idle_robot_indices:
                    # æ–¹å¼1ï¼šå¦‚æœæ¨¡å‹é€‰çš„å°è½¦ç©ºé—²â†’ç”¨æ¨¡å‹çš„é€‰æ‹©
                    if raw_action in idle_robot_indices:
                        action = raw_action
                    # æ–¹å¼2ï¼šæ¨¡å‹é€‰çš„å°è½¦å¿™ç¢Œâ†’éšæœºé€‰ä¸€ä¸ªç©ºé—²çš„ï¼ˆä¿è¯è®­ç»ƒä¸é˜»å¡ï¼‰
                    else:
                        action = random.choice(idle_robot_indices)
                        self.get_logger().debug(f"ğŸ“ è®­ç»ƒæ¨¡å¼ï¼šæ¨¡å‹é€‰å¿™ç¢Œå°è½¦{self.rl_env.robot_names[raw_action]}ï¼Œéšæœºé€‰ç©ºé—²å°è½¦{self.rl_env.robot_names[action]}")
                # é˜²æŠ¤2ï¼šæ— ç©ºé—²å°è½¦â†’éšæœºé€‰ä¸€ä¸ªï¼ˆä¿è¯è®­ç»ƒç»§ç»­ï¼‰
                else:
                    action = random.choice(all_robot_indices)
                    self.get_logger().debug(f"ğŸ“ è®­ç»ƒæ¨¡å¼ï¼šæ— ç©ºé—²å°è½¦ï¼Œéšæœºé€‰{self.rl_env.robot_names[action]}")
            else:
                # æç«¯æƒ…å†µï¼šæ¨¡å‹æœªåˆå§‹åŒ–â†’ä¼˜å…ˆé€‰ç©ºé—²ï¼Œæ— åˆ™éšæœº
                if idle_robot_indices:
                    action = random.choice(idle_robot_indices)
                else:
                    action = random.choice(all_robot_indices)
                self.get_logger().debug(f"ğŸ“ è®­ç»ƒæ¨¡å¼ï¼šæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œé€‰å°è½¦{self.rl_env.robot_names[action]}")
        
        elif self.mode == "infer":
            # æ¨ç†æ¨¡å¼ï¼šä¿ç•™åŸæœ‰é€»è¾‘ï¼ˆç¡®å®šæ€§é¢„æµ‹ï¼‰
            if self.model:
                action, _states = self.model.predict(obs, deterministic=True)
                # æ–°å¢é˜²æŠ¤ï¼šæ¨ç†æ—¶ä¹Ÿä¼˜å…ˆé€‰ç©ºé—²
                if idle_robot_indices and action not in idle_robot_indices:
                    action = random.choice(idle_robot_indices)
                    self.get_logger().warn(f"âš ï¸ æ¨ç†æ¨¡å¼ï¼šæ¨¡å‹é€‰å¿™ç¢Œå°è½¦ï¼Œéšæœºé€‰ç©ºé—²å°è½¦{self.rl_env.robot_names[action]}")
            else:
                # é™çº§ï¼šéšæœºé€‰ç©ºé—²å°è½¦ï¼Œæ— åˆ™éšæœº
                action = random.choice(idle_robot_indices) if idle_robot_indices else random.choice(all_robot_indices)
        else:
            self.get_logger().error(f"âŒ æ— æ•ˆæ¨¡å¼ï¼š{self.mode}")
            return
        
        # 4. æ‰§è¡ŒåŠ¨ä½œï¼ˆé€‰è½¦ï¼‰
        selected_robot = self.rl_env.robot_names[action]
        # æ—¥å¿—ï¼šè®°å½•é€‰è½¦ç»“æœ
        self.get_logger().info(f"ğŸ¯ å†³ç­–ç»“æœï¼šé€‰ä¸­{selected_robot}ï¼ˆç©ºé—²çŠ¶æ€ï¼š{self.rl_env.robot_idle[selected_robot]}ï¼‰")
        
        # 5. è·å–å¾…æ‰§è¡Œä»»åŠ¡
        task = self.rl_env.pending_tasks[0]
        task_id = task["task_id"]
        waypoint = task["waypoint"]
        
        # 6. è°ƒç”¨è‡ªå®šä¹‰ä»»åŠ¡æœåŠ¡ï¼ˆå³ä½¿å°è½¦å¿™ç¢Œä¹Ÿå‘é€ï¼Œä¿è¯è®­ç»ƒæœ‰åé¦ˆï¼‰
        self._call_nav_service(selected_robot, task_id, waypoint)


    def _call_nav_service(self, robot_name, task_id, waypoint):
        """è°ƒç”¨è‡ªå®šä¹‰ä»»åŠ¡æœåŠ¡å‘é€ä»»åŠ¡"""
        req = SingleNavTask.Request()
        req.target_waypoint = waypoint
        req.fleet_name = "deliveryRobot"
        req.robot_name = robot_name
        req.priority = 0
        
        # å¼‚æ­¥è°ƒç”¨æœåŠ¡
        future = self.nav_client.call_async(req)
        future.add_done_callback(lambda f: self._nav_service_response_callback(f, task_id, robot_name))
        
        self.get_logger().info(f"ğŸ“¤ å‘é€ä»»åŠ¡ï¼š{robot_name} -> {waypoint} (ä»»åŠ¡IDï¼š{task_id})")

    def _nav_service_response_callback(self, future, task_id, robot_name):
        """å¤„ç†æœåŠ¡å“åº”"""
        try:
            res = future.result()
            if res.success:
                self.get_logger().info(f"âœ… ä»»åŠ¡{task_id}å‘é€æˆåŠŸï¼Task ID: {res.task_id}")
                # æ ‡è®°ä»»åŠ¡ä¸ºæ‰§è¡Œä¸­ï¼ˆRLç¯å¢ƒï¼‰
                self.rl_env.robot_task_map[robot_name] = task_id
            else:
                self.get_logger().error(f"âŒ ä»»åŠ¡{task_id}å‘é€å¤±è´¥ï¼{res.message}")
                # ä»»åŠ¡å¤±è´¥ï¼šæ”¾å›é˜Ÿåˆ—
                target_waypoint = next(t["waypoint"] for t in self.rl_env.pending_tasks if t["task_id"] == task_id)
                target_coords = self.waypoint_coords[target_waypoint]
                self.rl_env.add_task(task_id, target_waypoint, target_coords.x, target_coords.y)
        except Exception as e:
            self.get_logger().error(f"ğŸ’¥ æœåŠ¡è°ƒç”¨å¼‚å¸¸ï¼š{str(e)}")

    def start_training(self, total_timesteps=100000):
        """å¼€å§‹è®­ç»ƒï¼ˆè®­ç»ƒæ¨¡å¼ä¸‹è°ƒç”¨ï¼‰"""
        if self.mode != "train":
            self.get_logger().error("âŒ éè®­ç»ƒæ¨¡å¼ï¼Œæ— æ³•å¼€å§‹è®­ç»ƒ")
            return
        
        self.get_logger().info(f"ğŸš€ å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°ï¼š{total_timesteps}")
        # å¼€å§‹è®­ç»ƒ
        self.model.learn(
            total_timesteps=total_timesteps,
            callback=self.checkpoint_callback,
            tb_log_name=f"dispatching_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.model.save("./rl_models/dispatching_ppo_final")
        self.get_logger().info("âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜ä¸ºdispatching_ppo_final")

# ===================== ç¬¬ä¸‰æ­¥ï¼šä¸»å‡½æ•°ï¼ˆæ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼‰ =====================
def main(args=None):
    rclpy.init(args=args)
    
    # åˆ›å»ºèŠ‚ç‚¹
    node = RLDispatcherNode()
    
    # è®­ç»ƒæ¨¡å¼ï¼šå¯åŠ¨è®­ç»ƒ
    if node.mode == "train":
        # å…ˆé‡ç½®RLç¯å¢ƒï¼ˆé€‚é…æ–°çš„resetæ¥å£ï¼‰
        node.rl_env.reset()
        
        # å¯åŠ¨è®­ç»ƒçº¿ç¨‹ï¼ˆå…³é”®ï¼šä¸é˜»å¡ROS spinï¼‰
        import threading
        train_thread = threading.Thread(
            target=node.start_training,
            args=(100000,),  # æ€»è®­ç»ƒæ­¥æ•°
            daemon=True
        )
        train_thread.start()
        
        # ä¸»çº¿ç¨‹è¿è¡ŒROS spin
        rclpy.spin(node)
        
        # ç­‰å¾…è®­ç»ƒçº¿ç¨‹ç»“æŸ
        train_thread.join()
    else:
        # æ¨ç†æ¨¡å¼ï¼šç›´æ¥spin
        rclpy.spin(node)
    
    # æ¸…ç†
    node.rl_env.close()  # å…³é—­ç¯å¢ƒ
    node.destroy_node()
    rclpy.shutdown()


if __name__ == "__main__":
    main()
